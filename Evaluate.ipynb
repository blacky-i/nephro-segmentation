{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59c73a6d",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "\n",
    "This notebook is intended for running model, measuring dice metric and creating predictions to `.nii.gz` files.\n",
    "\n",
    "NB: CT data is in [LPS orientation](https://www.slicer.org/wiki/Coordinate_systems) format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e1718d9",
   "metadata": {},
   "source": [
    "### Downloading data\n",
    "\n",
    "\n",
    "Data is available on Yandex.disk - https://disk.yandex.ru/d/pWEKt6D3qi3-aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "068a90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/pWEKt6D3qi3-aw'\n",
    "\n",
    "final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()['href']\n",
    "response = requests.get(download_url)\n",
    "\n",
    "dist_path = 'AVUCTK_cases.zip'\n",
    "with open(dist_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "    \n",
    "import zipfile\n",
    "with zipfile.ZipFile(dist_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b26ca37",
   "metadata": {},
   "source": [
    "### Preparing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18ed7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import monai \n",
    "\n",
    "MMAR_ROOT = 'kidney-mmar'\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'{MMAR_ROOT}/custom')\n",
    "from my_transforms import *\n",
    "\n",
    "KIDNEY_DATASET = f'dataset.json'\n",
    "DATASET_ROOT = os.getcwd()\n",
    "\n",
    "\n",
    "with open(KIDNEY_DATASET, 'r') as f:\n",
    "    dataset_json = json.load(f)\n",
    "\n",
    "model = torch.load(os.path.join(MMAR_ROOT,'models','model.pt'), map_location=torch.device('cpu'))\n",
    "train_config = model['train_conf']\n",
    "\n",
    "validation_with_root = [{\n",
    "                         'artery':obj['artery'],\n",
    "                         'vein':obj['vein'],\n",
    "                         'excret':obj['excret'],\n",
    "                         'label':obj['label']\n",
    "                        } for obj in dataset_json['validation']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32c53da4",
   "metadata": {},
   "source": [
    "### Creating preprocessing transforms pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93c8b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_transforms = []\n",
    "transform_map = {}\n",
    "for trfm in  train_config['train']['pre_transforms']:\n",
    "    if 'name' in trfm.keys():\n",
    "        key = trfm['name']\n",
    "        if '#' in key:\n",
    "            key = key.split('#')[1]\n",
    "        transform_map[key] = trfm\n",
    "for transform_json in train_config['validate']['pre_transforms']:\n",
    "    if 'ref' in transform_json.keys():\n",
    "        transform_name, transform_args = transform_map[transform_json['ref']]['name'], transform_map[transform_json['ref']]['args'] \n",
    "    elif 'name' in transform_json.keys():\n",
    "        transform_name, transform_args = transform_json['name'], transform_json['args']\n",
    "    else:\n",
    "        transform_name, transform_args = transform_json['path'], transform_json['args']\n",
    "    transform_name = transform_name.split('#')[0]\n",
    "    if '.' not in transform_name:\n",
    "        pre_transforms.append(getattr(monai.transforms,transform_name)(**transform_args))\n",
    "    else:\n",
    "        pre_transforms.append(ConcatImages(['artery','vein','excret'],'image'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c25d0d",
   "metadata": {},
   "source": [
    "### Creating postprocessing transforms pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65513a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transforms = []\n",
    "for transform_json in train_config['validate']['post_transforms']:\n",
    "    transform_name, transform_args = transform_json['name'], transform_json['args']\n",
    "    if monai.__version__ == '1.0.0':\n",
    "        if transform_name in ['AsDiscreteD','AsDiscreted']:\n",
    "            if 'threshold_values' in transform_args.keys():\n",
    "                if 'logit_thresh' in transform_args.keys():\n",
    "                    transform_args['threshold'] = [transform_args['logit_thresh'] if _ else None for _ in transform_args['threshold_values'] ]\n",
    "                else:\n",
    "                    transform_args['threshold'] = [_ if _ else None for _ in transform_args['threshold_values'] ]\n",
    "                del transform_args['threshold_values']\n",
    "                \n",
    "            if 'logit_thresh' in transform_args.keys():\n",
    "                del transform_args['logit_thresh']\n",
    "            if 'n_classes' in transform_args.keys():\n",
    "                transform_args['to_onehot'] = [transform_args['n_classes'] if _  else None for _ in transform_args['to_onehot'] ]\n",
    "                del transform_args['n_classes']\n",
    "    if transform_name == 'InvertD':\n",
    "        transform_args['transform'] = pre_transforms[3]\n",
    "        transform_args['device'] = 'cpu'\n",
    "    post_transforms.append(getattr(monai.transforms,transform_name)(**transform_args))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cb8a953",
   "metadata": {},
   "source": [
    "### Loading model and inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cd93ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')  if not torch.cuda.is_available() else torch.device('cuda:0')\n",
    "\n",
    "model = torch.load(os.path.join(MMAR_ROOT,'models','model.pt'), map_location=torch.device('cpu'))\n",
    "model_name, model_args = train_config['train']['model']['name'], train_config['train']['model']['args']\n",
    "model_arch = getattr(monai.networks.nets, model_name)(**model_args)\n",
    "model_arch.load_state_dict(model['model'])\n",
    "model_arch = model_arch.eval().to(device)\n",
    "\n",
    "inferer_name, inferer_args = train_config['validate']['inferer']['name'], train_config['validate']['inferer']['args']\n",
    "inferer = getattr(monai.inferers, inferer_name)(**inferer_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc9d5368",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Running all pipelines and saving prediction to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52e96862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file written: eval/case_1/pred_12_trans.nii.gz.\n",
      "file written: eval/case_2/pred_12_trans.nii.gz.\n",
      "file written: eval/case_3/pred_12_trans.nii.gz.\n",
      "file written: eval/case_4/pred_12_trans.nii.gz.\n",
      "file written: eval/case_5/pred_12_trans.nii.gz.\n",
      "file written: eval/case_6/pred_12_trans.nii.gz.\n",
      "file written: eval/case_7/pred_12_trans.nii.gz.\n",
      "file written: eval/case_8/pred_12_trans.nii.gz.\n",
      "file written: eval/case_9/pred_12_trans.nii.gz.\n",
      "|           Dice metric statistics            |\n",
      "===============================================\n",
      "| Artery | Vein | Urethra | Neoplasm | Kidney |\n",
      "===============================================\n",
      "|  0.86  | 0.80 |  0.80   |   0.58   |  0.89  |\n",
      "-----------------------------------------------\n",
      "| Mean =                 0.79                 |\n"
     ]
    }
   ],
   "source": [
    "save_transform = monai.transforms.SaveImaged(keys=['pred'],\n",
    "                                             separate_folder=False,\n",
    "                                             output_dtype=np.uint8,\n",
    "                                             meta_keys=['pred_meta_dict'],\n",
    "                                             data_root_dir='data',\n",
    "                                             output_dir=f'eval'\n",
    "                                            )\n",
    "dices = []\n",
    "for out in validation_with_root:\n",
    "    case = out['artery'].split('/')[-2]\n",
    "    for trfm in pre_transforms:\n",
    "        out = trfm(out)\n",
    "    with torch.no_grad():\n",
    "        out['pred'] = inferer(out['image'].unsqueeze(0).to(device), model_arch)\n",
    "    out['label'] = out['label'].unsqueeze(0)\n",
    "    out['pred'] = out['pred'].squeeze()\n",
    "    for trfm in post_transforms:\n",
    "        out = trfm(out)\n",
    "    out['pred_meta_dict'] = copy.copy(out['image_meta_dict'])\n",
    "    new_pred = out['pred_meta_dict']['filename_or_obj'].split('/')\n",
    "    new_pred[-1] = 'pred_' + new_pred[-1]\n",
    "    out['pred_meta_dict']['filename_or_obj'] = '/'.join(new_pred)\n",
    "    out['label'] = out['label'].permute(1,0,2,3,4)\n",
    "    out['pred'] = out['pred'].unsqueeze(0)\n",
    "    if out['pred'].shape == out['label'].shape:\n",
    "        dice = monai.metrics.compute_meandice(out['pred'].cpu(),out['label'].cpu(), False)\n",
    "        dices.append(dice)\n",
    "    out['pred_meta_dict'] = copy.copy(out['image_meta_dict'])\n",
    "    new_pred = out['pred_meta_dict']['filename_or_obj'].split('/')\n",
    "    new_pred[-1] = 'pred_' + new_pred[-1]\n",
    "    out['pred_meta_dict']['filename_or_obj'] = '/'.join(new_pred)\n",
    "    merged = None\n",
    "    for idx, channel in enumerate(out['pred'].squeeze()  * torch.tensor([0,1,2,3,4,5]).view(-1,1,1,1)):\n",
    "        imgvol = channel\n",
    "        if idx != 6:\n",
    "            if merged is not None:\n",
    "                merged = merged + imgvol * ~((merged != 0) & (imgvol != 0))\n",
    "            else:\n",
    "                merged = imgvol\n",
    "    out['pred'] = merged.unsqueeze(0).cpu().numpy()\n",
    "    save_transform(out)\n",
    "\n",
    "header = ['Artery', 'Vein', 'Urethra', 'Neoplasm', 'Kidney']\n",
    "\n",
    "print('| {:^43} |'.format('Dice metric statistics'))\n",
    "print('='*47)\n",
    "print('| {:} | {:} | {:} | {:} | {:} |'.format(*header))\n",
    "print('='*47)\n",
    "print('| {:^6.2f} | {:^4.2f} | {:^7.2f} | {:^8.2f} | {:^6.2f} |'.format(*torch.cat(dices).mean(0).cpu().numpy()))\n",
    "print('-'*47)\n",
    "print('| Mean = {:^36.2f} |'.format(torch.cat(dices).mean().cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0db2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
